services:
  # lp-det:
  #   image: ./dreamteam/lp-det:test
  #   # command: poetry shell && lp-det-train
  
  app:
    build:
      dockerfile: ./lp-det/Dockerfile.gpu
    environment:
      - VIRTUAL_ENV=/opt/venv
      - PATH=/opt/venv/bin:$PATH
      - DEBIAN_FRONTEND=noninteractive
      - DISPLAY=${DISPLAY}
    privileged: true
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
    #use gpu
    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix
      - .:/opt/app
      - /home/edargham:/host-in
    ports:
      - "8000:8000"
    networks:
      - app-network
    command: ["--source", "/host-in/Test.mp4"]

  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml
    ports:
      - "9090:9090"
    networks:
      - app-network
    depends_on:
      - app

  alertmanager:
    image: prom/alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    networks:
      - app-network
    depends_on:
      - prometheus

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    networks:
      - app-network
    depends_on:
      - prometheus
  
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.19.0
    ports:
      - 5050:5000
    environment:
      MLFLOW_TRACKING_URI: http://127.0.0.1:5000
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --host 0.0.0.0
    volumes:
      - ./lp-det/models:/mlflow/artifacts

networks:
  app-network:
    driver: bridge

volumes:
  mlflow-artifacts: